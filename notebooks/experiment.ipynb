{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "import dagshub\n",
    "import pickle\n",
    "from loguru import logger\n",
    "from pathlib import Path\n",
    "from mlflow.models import infer_signature\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    RocCurveDisplay,\n",
    ")\n",
    "from src.config import DATA_DISK, CONFUSION_MATRIX_DIR, ROC_CURVE_DIR, MODELS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_path: Path = MODELS_DIR / \"model.pkl\"\n",
    "cm_path: Path = CONFUSION_MATRIX_DIR / \"confusion_matrix.png\"\n",
    "roc_path: Path = ROC_CURVE_DIR / \"roc_curve.png\"\n",
    "\n",
    "dagshub.init(repo_owner=\"minhquana1906\", repo_name=\"water_potability_prediction\", mlflow=True)\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/minhquana1906/water_potability_prediction.mlflow\")\n",
    "mlflow.set_experiment(\"Experiment 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def fill_missing_with_mean(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_DISK)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_processed_data = fill_missing_with_mean(train_data)\n",
    "test_processed_data = fill_missing_with_mean(test_data)\n",
    "\n",
    "X_train = train_processed_data.drop(columns=[\"Potability\"], axis=1)\n",
    "y_train = train_processed_data[\"Potability\"]\n",
    "X_test = test_processed_data.drop(columns=[\"Potability\"], axis=1)\n",
    "y_test = test_processed_data[\"Potability\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Implement RandomizedSearchCV for hyperparameter tuning\n",
    "param_dist = {\n",
    "    \"n_estimators\": [50, 200, 500, 800, 1000, 1200],\n",
    "    \"max_depth\": [None, 3, 9, 15, 30],\n",
    "    \"min_samples_split\": [2, 8, 15, 100],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    scoring=\"accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=f\"Random Forest Tuning\") as parent_run:\n",
    "    logger.info(f\"Training Random Forest model with hyperparameter tuning...\")\n",
    "    search.fit(X_train, y_train)\n",
    "    for i in range(len(search.cv_results_[\"params\"])):\n",
    "        with mlflow.start_run(run_name=f\"Combination {i}\", nested=True) as children_run:\n",
    "            mlflow.log_params(search.cv_results_[\"params\"][i])\n",
    "            mlflow.log_metric(\"mean_test_score\", search.cv_results_[\"mean_test_score\"][i])\n",
    "\n",
    "    logger.info(f\"Best parameters: {search.best_params_}\")\n",
    "    logger.info(\"Logging best params to MLflow...\")\n",
    "    mlflow.log_params(search.best_params_)\n",
    "\n",
    "    logger.info(f\"Training model with parameters: {search.best_params_}\")\n",
    "    # model.set_params(**search.best_params_)\n",
    "    model = search.best_estimator_\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    logger.info(f\"Evaluating model...\")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    logger.info(f\"Logging metrics to MLflow...\")\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"f1 score\", f1)\n",
    "\n",
    "    # mlflow.sklearn.log_model(model, model_name)\n",
    "\n",
    "    logger.info(f\"Saving model to {model_path}...\")\n",
    "    pickle.dump(model, open(model_path, \"wb\"))\n",
    "\n",
    "    logger.info(f\"Logging model to MLflow...\")\n",
    "    signature = infer_signature(X_train, model.predict(X_train))\n",
    "    mlflow.sklearn.log_model(model, \"RandomForestClassifier\", signature=signature)\n",
    "\n",
    "    logger.info(f\"Generating confusion matrix and ROC curve and logging to MLflow...\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm_display = ConfusionMatrixDisplay(cm).plot(\n",
    "        cmap=\"Blues\",\n",
    "        values_format=\"d\",\n",
    "    )\n",
    "    plt.savefig(cm_path)\n",
    "    mlflow.log_artifact(cm_path)\n",
    "\n",
    "    roc = roc_auc_score(y_test, y_pred)\n",
    "    fpr, tpr = roc_curve(y_test, y_pred)[:2]\n",
    "    roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()\n",
    "    plt.savefig(roc_path)\n",
    "    mlflow.log_artifact(roc_path)\n",
    "\n",
    "    logger.info(f\"Logging source code file to MLflow...\")\n",
    "    mlflow.log_artifact(__file__)\n",
    "\n",
    "    logger.info(f\"Logging dataset to MLflow...\")\n",
    "    train_df = mlflow.data.from_pandas(train_processed_data)\n",
    "    test_df = mlflow.data.from_pandas(test_processed_data)\n",
    "    mlflow.log_input(train_df, \"train\")\n",
    "    mlflow.log_input(test_df, \"test\")\n",
    "\n",
    "    logger.success(f\"Experiment completed successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
